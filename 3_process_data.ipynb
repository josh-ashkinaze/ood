{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2d3a7e-3c66-426e-82ef-69dad0c5b0c5",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949f2ccb-9aca-45cb-85b4-7553674fb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.metrics import pairwise_distances as pdist\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "np.random.seed(416)\n",
    "random.seed(416)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641522f7-cc2b-40a8-98d2-7273e2bc8012",
   "metadata": {},
   "source": [
    "# Clean AI responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4dc716-20da-4dc9-baa2-384a02bc55df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Number of AI ideas 900\n",
      "Number of AI ideas by domain and model                         output  dataset_id\n",
      "category model                            \n",
      "opeds    claude-2          100         100\n",
      "         gpt-3.5-turbo     100         100\n",
      "         gpt-4-0613        100         100\n",
      "podcasts claude-2          100         100\n",
      "         gpt-3.5-turbo     100         100\n",
      "         gpt-4-0613        100         100\n",
      "startups claude-2          100         100\n",
      "         gpt-3.5-turbo     100         100\n",
      "         gpt-4-0613        100         100\n",
      "==================================================\n",
      "Error: Expecting ',' delimiter: line 1 column 708 (char 707)\n",
      "Response: {\"description\": \"Welcome to 'Invisible Threads,' an immersive podcast journey where we unravel the unseen ties that connect us all. Each episode is a deep dive into the intricate world of culture, science, history, and the collective human experience. Join our host, renowned anthropologist Dr. Emma Robinson, as she navigates through compelling stories, mind-bending theories, and engaging dialogues with leading experts from diverse fields. Tune in for a unique blend of gripping narratives, insightful analysis, and enlightened conversation. 'Invisible Threads,' - unveiling the extraordinary in the ordinary. Don't just listen, feel the connection. Unscripted, unpretentious, and absolutely unmissable!\".}\n",
      "\n",
      "Error: Expecting ',' delimiter: line 1 column 257 (char 256)\n",
      "Response: {\"description\": \"Welcome to 'Chronicles of the Unseen,' a captivating podcast that journeys into the mystic, transcending the boundaries of ordinary reality. Each week, we explore unsolved mysteries, paranormal phenomena, and everything that's considered \"otherworldly.\" Join us as we dig deep into alien encounters, signals from the beyond, haunting ghost stories, and uncover secrets of the universe. 'Chronicles of the Unseen' - a podcast for the curious, fascinated, and brave. Tune in and let your mind wander into the realms of infinite possibilities. }\"}\n",
      "\n",
      "Error: Invalid control character at: line 1 column 298 (char 297)\n",
      "Response:  {\"description\": \"Welcome to the Podcast Experts podcast! I'm your host, Mike, a longtime podcaster with over a decade of experience creating successful shows. On this podcast we dive deep into the world of podcasting to help both new and experienced podcasters take their shows to the next level. \n",
      "\n",
      "In each episode we breakdown the strategies, tools, and mindsets you need to launch a podcast, grow an audience, land big name guests, get sponsors, quit your day job and turn your passion into a profitable podcast business. Whether you’re just starting out or already have an established show, you’ll learn the insider secrets used by top hosts. Fasten your headphones and get ready for the ultimate podcasting masterclass!\"}\n",
      "\n",
      "==================================================\n",
      "Number of nans: 3\n",
      "          model  category\n",
      "746  gpt-4-0613  podcasts\n",
      "794  gpt-4-0613  podcasts\n",
      "860    claude-2  podcasts\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def fix_cat(x):\n",
    "    if x == \"startup\":\n",
    "        return \"startups\"\n",
    "    elif x == \"oped\":\n",
    "        return \"opeds\"\n",
    "    elif x== \"podcast\":\n",
    "        return \"podcasts\"\n",
    "        \n",
    "def extract_json(text):\n",
    "    try:\n",
    "        matches = re.findall(r'\\{[^{}]*\\}', text)\n",
    "        if matches:\n",
    "            json_str = matches[0]\n",
    "            data = json.loads(json_str)\n",
    "            if len(data.keys()) == 1:\n",
    "                return list(data.values())[0]\n",
    "            else:\n",
    "                raise ValueError(\"More than 1 key\")\n",
    "        else:\n",
    "            raise ValueError(\"No JSON found in the provided text.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\\nResponse: {text}\\n\")\n",
    "        return np.nan\n",
    "\n",
    "# Example usage\n",
    "\n",
    "##############\n",
    "# Read in and fix cat col\n",
    "##############\n",
    "\n",
    "ai_ideas = pd.read_json(\"ai_ideas.jsonl\", lines=True)\n",
    "ai_ideas['category'] = ai_ideas['category'].apply(fix_cat)\n",
    "\n",
    "##############\n",
    "# Simple stats\n",
    "##############\n",
    "print(\"=====\"*10)\n",
    "print(\"Number of AI ideas\", len(ai_ideas))\n",
    "print(\"Number of AI ideas by domain and model\", ai_ideas.groupby(by=['category', 'model']).count())\n",
    "print(\"=====\"*10)\n",
    "\n",
    "\n",
    "##############\n",
    "# Coerce json data\n",
    "##############\n",
    "ai_ideas['text'] = ai_ideas['output'].apply(extract_json)\n",
    "\n",
    "##############\n",
    "# Drop NaNs\n",
    "##############\n",
    "print(\"=====\"*10)\n",
    "print(f\"Number of nans:\", np.sum(ai_ideas['text'].isna()))\n",
    "print(ai_ideas[ai_ideas['text'].isna()][['model', 'category']])\n",
    "print(\"=====\"*10)\n",
    "\n",
    "ai_ideas = ai_ideas.dropna(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356cb982-86fa-4dea-954f-0ba2976c1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>category</th>\n",
       "      <th>output</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>startups</td>\n",
       "      <td>{\"idea\": \"A platform that connects remote work...</td>\n",
       "      <td>gpt-3.5-turbo_startup_2</td>\n",
       "      <td>A platform that connects remote workers with l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>claude-2</td>\n",
       "      <td>opeds</td>\n",
       "      <td>Here is a suggested op-ed headline for the Ne...</td>\n",
       "      <td>claude-2_oped_54</td>\n",
       "      <td>America's Uncertain Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>startups</td>\n",
       "      <td>{\"idea\": \"A platform that helps users find and...</td>\n",
       "      <td>gpt-3.5-turbo_startup_33</td>\n",
       "      <td>A platform that helps users find and connect w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>claude-2</td>\n",
       "      <td>podcasts</td>\n",
       "      <td>{\"description\": \"Welcome to the Podcast Pros ...</td>\n",
       "      <td>claude-2_podcast_10</td>\n",
       "      <td>Welcome to the Podcast Pros podcast, where we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>startups</td>\n",
       "      <td>{\"idea\": \"An AI-powered platform that connects...</td>\n",
       "      <td>gpt-4-0613_startup_57</td>\n",
       "      <td>An AI-powered platform that connects young pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model  category  \\\n",
       "2    gpt-3.5-turbo  startups   \n",
       "554       claude-2     opeds   \n",
       "33   gpt-3.5-turbo  startups   \n",
       "810       claude-2  podcasts   \n",
       "157     gpt-4-0613  startups   \n",
       "\n",
       "                                                output  \\\n",
       "2    {\"idea\": \"A platform that connects remote work...   \n",
       "554   Here is a suggested op-ed headline for the Ne...   \n",
       "33   {\"idea\": \"A platform that helps users find and...   \n",
       "810   {\"description\": \"Welcome to the Podcast Pros ...   \n",
       "157  {\"idea\": \"An AI-powered platform that connects...   \n",
       "\n",
       "                   dataset_id  \\\n",
       "2     gpt-3.5-turbo_startup_2   \n",
       "554          claude-2_oped_54   \n",
       "33   gpt-3.5-turbo_startup_33   \n",
       "810       claude-2_podcast_10   \n",
       "157     gpt-4-0613_startup_57   \n",
       "\n",
       "                                                  text  \n",
       "2    A platform that connects remote workers with l...  \n",
       "554                         America's Uncertain Future  \n",
       "33   A platform that helps users find and connect w...  \n",
       "810  Welcome to the Podcast Pros podcast, where we ...  \n",
       "157  An AI-powered platform that connects young pro...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_ideas.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f712d-da8a-4e5c-aa32-ec41c1da1bf7",
   "metadata": {},
   "source": [
    "# Read in human responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55875de6-ad20-4e77-b4ea-7e101dd30d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3277578/4274664311.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brief_opeds['date'] = pd.to_datetime(brief_opeds['date'])\n",
      "/tmp/ipykernel_3277578/4274664311.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  brief_opeds['category'] = 'opeds'\n"
     ]
    }
   ],
   "source": [
    "# Opeds\n",
    "opeds = pd.read_json(\"2017-01-01_to_2024-04-15_nyt_headlines.jsonl\", lines=True)\n",
    "brief_opeds = opeds[['abstract', 'date', 'dataset_id']]\n",
    "brief_opeds['date'] = pd.to_datetime(brief_opeds['date'])\n",
    "brief_opeds.columns = ['text', 'date', 'dataset_id']\n",
    "brief_opeds['category'] = 'opeds'\n",
    "\n",
    "# # Startups\n",
    "startups = pd.read_json(\"2017-01-01_to_2024-04-15_startups.jsonl\", lines=True)\n",
    "brief_startups = startups[['description', 'date', 'dataset_id']]\n",
    "brief_startups.columns = ['text', 'date', 'dataset_id']\n",
    "brief_startups['category'] = 'startups'\n",
    "\n",
    "brief_human = pd.concat([brief_startups, brief_opeds])\n",
    "brief_human['date'] = pd.to_datetime(brief_human['date'], utc=True).dt.date\n",
    "\n",
    "brief_human.to_json(\"brief_human.jsonl\", lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99d25bb-4223-4774-a0b6-2eda494be674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>Collaboration and meeting software for Virtual...</td>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>startup_5035</td>\n",
       "      <td>startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>Remote work advice just for you</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>startup_19096</td>\n",
       "      <td>startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28218</th>\n",
       "      <td>Free polling and survey</td>\n",
       "      <td>2021-11-13</td>\n",
       "      <td>startup_28218</td>\n",
       "      <td>startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>Free Typeform alternative with next-level calc...</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>startup_23702</td>\n",
       "      <td>startups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Some alterations to the A.C.A. proposed by the...</td>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>oped_1974</td>\n",
       "      <td>opeds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        date  \\\n",
       "5035   Collaboration and meeting software for Virtual...  2017-11-20   \n",
       "19096                    Remote work advice just for you  2020-05-05   \n",
       "28218                            Free polling and survey  2021-11-13   \n",
       "23702  Free Typeform alternative with next-level calc...  2021-02-18   \n",
       "1974   Some alterations to the A.C.A. proposed by the...  2017-07-13   \n",
       "\n",
       "          dataset_id  category  \n",
       "5035    startup_5035  startups  \n",
       "19096  startup_19096  startups  \n",
       "28218  startup_28218  startups  \n",
       "23702  startup_23702  startups  \n",
       "1974       oped_1974     opeds  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brief_human.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eefae2-02c5-4a2b-84ba-53b461477c22",
   "metadata": {},
   "source": [
    "# Sbert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd6715-0f1c-4a65-88fa-56fb3cf73c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d46dee81dd64dee80d5c0e589dce579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1536 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "human_embeddings = model.encode(brief_human['text'].tolist(), show_progress_bar=True)\n",
    "ai_embeddings = model.encode(ai_ideas['output'].tolist(), show_progress_bar=True)\n",
    "\n",
    "brief_human['vec'] = [i for i in human_embeddings]\n",
    "ai_ideas['vec'] = [i for i in ai_embeddings]\n",
    "\n",
    "brief_human.to_json(\"brief_human_w_vec.jsonl\", lines=True, orient='records')\n",
    "ai_ideas.to_json(\"ai_ideas_w_vec.jsonl\", lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442597a-df75-491a-8ebc-eadc29909b3d",
   "metadata": {},
   "source": [
    "# Save files for analysis\n",
    "\n",
    "Object properties:\n",
    "- `vec`: The SBERT embedding of text\n",
    "- `dataset_id`: A textual id (e.g: `gpt4_startup_0`)\n",
    "- `idx`: Every idea assigned a unique index, which is useful for slicing the similarity matrix\n",
    "\n",
    "Pickle files created:\n",
    "- `dataset_id2idx`\n",
    "- `idx2dataset_id`\n",
    "- `idx2vec`\n",
    "- `dataset_id2vec`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76392a80-69dc-414d-aa7b-03ffbb4a7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dids = brief_human['dataset_id'].tolist() + ai_ideas['dataset_id'].tolist()\n",
    "vecs = brief_human['vec'].tolist() + ai_ideas['vec'].tolist()\n",
    "comb = pd.DataFrame({'dataset_id':dids, 'vec':vecs})\n",
    "comb['idx'] = [i for i in range(len(comb))]\n",
    "\n",
    "# Different dictionaries and mappings\n",
    "data_dict = {\n",
    "    \"dataset_id2idx\": comb.set_index('dataset_id')['idx'].to_dict(),\n",
    "    \"idx2dataset_id\": comb.set_index('idx')['dataset_id'].to_dict(),\n",
    "    \"idx2vec\": comb.set_index('idx')['vec'].to_dict(),\n",
    "    \"dataset_id2vec\": comb.set_index('dataset_id')['vec'].to_dict()\n",
    "}\n",
    "\n",
    "for filename, data in data_dict.items():\n",
    "    with open(f\"{filename}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data, file)\n",
    "        print(f'Created {filename}.pkl')\n",
    "\n",
    "\n",
    "# One master similarity matrix so we don't have to re-compute\n",
    "vec_array = np.array(comb['vec'].tolist())\n",
    "cdist = pdist(vec_array, metric='cosine', n_jobs=-1)  \n",
    "csim = 1 - cdist  \n",
    "np.fill_diagonal(csim, 1)\n",
    "with open('sim_mat.pkl', 'wb') as file:\n",
    "    pickle.dump(csim, file)\n",
    "    print(\"Created sim mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5fccf-142d-45bf-8cee-b9f75cc1cb87",
   "metadata": {},
   "source": [
    "# Create domain-level datasets for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8267b4",
   "metadata": {},
   "source": [
    "## Simple pairwise differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a48263",
   "metadata": {},
   "source": [
    "`pw_data.csv` has triplets like `(human_id, ai_id, sim)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9cfca-b3d2-49b8-95ed-c18a5633d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "\n",
    "cpus = os.cpu_count()\n",
    "cpus_to_use = min(8, cpus-4)\n",
    "\n",
    "\n",
    "with open('sim_mat.pkl', 'rb') as file:\n",
    "    csim = pickle.load(file)  # Load the similarity matrix\n",
    "\n",
    "with open('dataset_id2idx.pkl', 'rb') as file:\n",
    "    dataset_id2idx = pickle.load(file)  \n",
    "\n",
    "def process_ai_idea(ai_ids_batch, human_ids, csim, dataset_id2idx):\n",
    "    results = []\n",
    "    human_idxs = [dataset_id2idx[human_id] for human_id in human_ids]\n",
    "    for ai_id in ai_ids_batch:\n",
    "        ai_idx = dataset_id2idx[ai_id]\n",
    "        sim_scores = csim[ai_idx][human_idxs]\n",
    "        for human_id, sim in zip(human_ids, sim_scores):\n",
    "            combined_row = {'ai_id': ai_id, 'human_id': human_id, 'sim': sim}\n",
    "            results.append(combined_row)\n",
    "    return results\n",
    "\n",
    "\n",
    "domains = ['startups', 'opeds']\n",
    "pw_data = []\n",
    "cpus_to_use = min(8, os.cpu_count() - 4)\n",
    "batch_size = 128  \n",
    "\n",
    "for domain in domains:\n",
    "    print(\"Processing domain: \", domain)\n",
    "    human_ids = brief_human.query(f\"category == '{domain}'\")['dataset_id'].tolist()\n",
    "    ai_ids = ai_ideas.query(f\"category == '{domain}'\")['dataset_id'].tolist()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=cpus_to_use) as executor:\n",
    "        ai_id_batches = [ai_ids[i:i + batch_size] for i in range(0, len(ai_ids), batch_size)]\n",
    "        futures = [executor.submit(process_ai_idea, batch, human_ids, csim, dataset_id2idx) for batch in ai_id_batches]\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing {domain} domain\"):\n",
    "            pw_data.extend(future.result())\n",
    "\n",
    "pw_df = pd.DataFrame(pw_data)\n",
    "print(\"Got pw data\")\n",
    "pw_df.to_csv(\"all_pw_data.csv\")\n",
    "print(\"Data has been written to all_pw_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27152ef",
   "metadata": {},
   "source": [
    "## Make enriched file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba9c15",
   "metadata": {},
   "source": [
    "`pw_data_enriched` has enriched columns: \n",
    "\n",
    "`['date', 'dataset_id', 'category', 'ai_id', 'human_id', 'sim', 'model','in_window']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(brief_human, pw_df, left_on=['dataset_id'], right_on=['human_id'])\n",
    "merged = merged[[x for x in merged.columns if 'vec' not in x and 'text' not in x]]\n",
    "merged['model'] = merged['ai_id'].apply(lambda x: x.split(\"_\")[0])\n",
    "merged['date'] = pd.to_datetime(merged['date'])\n",
    "merged['claude_window'] = (merged['date'] <= \"2023-04-01\").astype(int)\n",
    "merged['gpt_window'] = (merged['date'] <= \"2021-10-01\").astype(int)\n",
    "merged['in_window'] = np.where(merged['model'] == 'chatgpt', merged['gpt_window'], merged['claude_window'])\n",
    "merged['in_window_str'] =merged['in_window'].apply(lambda x: \"Inside Training Window\" if x==1 else \"Outside Training Window\")\n",
    "bad_cols = [x for x in merged.columns if 'window' in x and x != 'in_window']\n",
    "merged = merged[[x for x in merged.columns if x not in bad_cols]]\n",
    "print(\"Made pw_data_enriched\")\n",
    "merged.to_csv(\"all_pw_data_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7936e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
